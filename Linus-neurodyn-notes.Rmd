---
output:
  html_document:
    df_print: paged
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---
```{python}
# %load_ext rpy2.ipython
```

```{r}
library(tidyverse)
```


# Learning Simulations
These are my notes for going through the excercises in the neuronal dynamics textbook.


```{python}
# Import brian
from brian2 import *
# data frame support and `tidy` plotting
import pandas as pd
import numpy as np
# ggplot port to python
from plotnine import *
#activate inline use of matplotlib
# %matplotlib inline
```

Define a very simple neuron with this syntax.
The text in the apostrophe environment are the differential equations that define the behaviour.


```{python}
tau = 10*ms             # a time constant
eqs = '''
dv/dt = (1-v)/tau : 1
'''
```

Now we can put the equation into a neuron.
The equation formally typed out:
\begin{equation}
\frac{\partial v}{\partial t} = \frac{(1-v)}{\tau}
\end{equation}
This equation is a simple exponential decay with $\tau$ time constant.

\begin{equation}
v(t) = 1-\exp\left(\frac{-t}{\tau}\right)
\end{equation}

## Simulating and plotting from a single Neuron
Next we assign a Neuron with that voltage equation.
Neurons are always assigned as a neuron group.

```{python}
G = NeuronGroup(1, eqs)
```

Now we can simulate the timecourse with the run command.

```{python}
start_scope()

run(100*ms)
```

Next, we would like to simulate and look at different aspects of the model as it evolves in time.
Variables of the model at a given point in time are referred to as *states* by brian.
The following block simulates and records the time course of voltage based on the model (it should just be an exponential asymptote to 1)



```{python}
start_scope()

G = NeuronGroup(1, eqs, method='exact')
M = StateMonitor(G, 'v', record=0)

run(30*ms)

# plot(M.t/ms, M.v[0])
# xlabel('Time (ms)')
# ylabel('v');
```

State monitor objects are used to store the information of a run.
The neurons have to be specified (here: `record = 0` option) in order to preserve memory.

Now we can introduce spiking behaviour.
Whenever the threshold is reached, voltage gets set to 0, and decays with the defined equation.
These can both be specified in the neuron specification.

```{python}
start_scope()

tau = 10*ms
eqs = '''
dv/dt = (1-v)/tau : 1
'''

G = NeuronGroup(2, eqs, threshold='v>0.8', reset='v = 0', method='exact')

M = StateMonitor(G, 'v', record=True)
spikemon = SpikeMonitor(G)

run(50*ms)
plot(M.t/ms, M.v[0])
xlabel('Time (ms)')
ylabel('v');
```

`StateMonitor` are 2D arrays with the index of the neuron, and the value of the timecourse.
This *should* lend itself to create tidy dataframes from this.
It can be done with the `get.states` syntax (requires pandas).

```{python}
simdata = pd.DataFrame({
    'N': len(M.v),
    't': M.t,
    'V': M.v[0]})

```

This produces the output I want from this one, but is not quite what I want yet, we can go back to it.
Want to have a tidy format dataframe generated from a `StateMonitor` call that can handle multiple variables and neurons.
Should be doable with for loops.

Pseudocode:

* For each neuron in number_neurons
    - do a call to get states that produces a tidy output for that neuron
* then append these tidy frames to each other with a neuron index variable
* assign that to the main environment

Plotnine is the graphing library that should come close to functionaity to ggplot and has a tidy working paradigm.
Try to explore the tidy set created and make a line plot.


This should also be possible with np reshape commands.

```{python}
(ggplot(simdata, aes(x = 't', y = 'V', colour = 'N'))
+ geom_line())
```

Brian can register spikes in the simulation.
This has been done by assigning the spike monitor command.

```{python}
start_scope()

G = NeuronGroup(1, eqs, threshold='v>0.4', reset='v = 0.2', method='exact')

statemon = StateMonitor(G, 'v', record=0)
spikemon = SpikeMonitor(G)

run(50*ms)

# update the simdataframe 
simdata = pd.DataFrame({
    'N': len(statemon.v),
    't': statemon.t,
    'V': statemon.v[0]})
```

```{python}
print('Spike times: %s' % spikemon.t[:])
```

```{python}
spikesdf = pd.DataFrame({'spikes': spikemon.t/ms /1000})
```

Now we can plot the extracted spikes, on top of the timecourse.


```{python}
(ggplot(simdata, aes(x = 't', y = 'V'))
+ geom_line(colour = 'blue')
+ geom_vline(aes(xintercept = 'spikes'), data = spikesdf, linetype = 'dotted')
+ theme_bw())
```

You can introduce refractoryness to the model by adding a refractory dead time.

```{python}
start_scope()

tau = 10*ms
eqs = '''
dv/dt = (1-v)/tau : 1 (unless refractory)
'''

# The neuron with refractory time
G = NeuronGroup(1, eqs, threshold='v>0.8', reset='v = 0', refractory=5*ms, method='exact')

statemon = StateMonitor(G, 'v', record=0)
spikemon = SpikeMonitor(G)

run(50*ms)

# update the simdataframe 
simdata = pd.DataFrame({
    'N': len(statemon.v),
    't': statemon.t,
    'V': statemon.v[0]})

# update the spikes
spikesdf = pd.DataFrame({'spikes': spikemon.t/ms /1000})

# plot it
(ggplot(simdata, aes(x = 't', y = 'V'))
+ geom_line(colour = 'blue')
+ geom_vline(aes(xintercept = 'spikes'), data = spikesdf, linetype = 'dotted')
+ theme_bw())
```

What I did not like about the `plotnine` is that its ggpleot implementation seems to be very sensitive about types and spazzes out immediatly on that, whereas usually R will just throw a warning about continous vs other data.

Altair is another plotting library that looks very clean and is also ignorant about types.

```{python}
import altair as alt

#tc plot
tc_chart = alt.Chart(simdata).mark_line().encode(
    x = 't:Q', 
    y = 'V:Q'  # Quantitative variable
)

#plot of the spike value with vertical line
spike_chart = alt.Chart(spikesdf).mark_rule(strokeDash=[5,5]).encode(
    x = 'spikes:Q'
)

# combine and print
alt.layer(tc_chart,spike_chart)
```

While not as straightforward as ggplot the syntax and output is simple and prety enough.

## Simulating multiple Neurons

Next are going to produce ouput for many neuron.

```{python}
start_scope()
n_neurons = 100         # Number of neurons
tau = 10*ms             # time constant

# same equation as before but the asymtone is now 2
eqs = '''          
dv/dt = (2-v)/tau : 1 
''' 
# A network of 100 neurons
net_100 = NeuronGroup(n_neurons, eqs, threshold='v>1', reset='v=0', method='exact')
# this gives every neuron a different starting value for the voltage at t0
net_100.v = 'rand()' 

spikemon = SpikeMonitor(net_100) # this records the spiketimes

run(50*ms)

```

Now we need to clean the spikemonitor variable.
It contains variables `i` (neuron index) and `t` (spiketime).
They are arrays containing just one vector (dimension `(n_spikes,)`) and have the same length.
Tidying should therefore be easy.

There is a method implemented for `SpikeMonitor` objects that will return a dictionary object of the values, with the umber of the neuron as index.
Problem is it produces an array with a unit.

```{python}
spikemon.all_values()['t'][0]
```

Despite this, pandas allows import, however, the data is now in wide format with the neuron as rows.
So we need to do some wrangling and pivoting.

```{python}
spikes_wide = pd.DataFrame.\
from_dict(spikemon.all_values()['t'],
          orient = 'index')

# pandas for some reason loves rownames, which pisses me off coming from R
# we need to get the information stored in there!
spikes_wide.index.name = 'neuron'
spikes_wide.reset_index(inplace=True)

# pivot longer by neuron
spikes_long = spikes_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,8)),
                               var_name = 'spikeno',
                               value_name = 't')
# tidy and update the thing
spikes_long = spikes_long.sort_values(['neuron', 'spikeno'])
# drop NA values
spikes_long = spikes_long.dropna()
spikes_long
```

This looks fine, but trying to wrangle more I got massive problems because the data types are rubbish.

```{python}
spikes_long.dtypes
```

```{python}
spikes_long['t'].str.split(expand = True)
```

My plan was to treat the compound unt datatype as string and then extract the actual number.
That does not work and throws an error.
To get the number I need to apply the `/ms` syntax from the unit data type from brian.
That works only in a vectorised way if you have a numpy array.
Now it all lives in pandas.
We can do it on an individual datum though.


```{python}
spikes_long['t'][1]

```

```{python}
spikes_long['t'][1]/ms

```

```{python}
#vectorised is gets rid of something but not quite...
spikes_long['t']/ms
```

```{python}
# try assiging a new column (mutate style in R)
spikes_long.assign(spiket = spikes_long['t'] /ms)
```

It does not work, we need to do it row-wise!
Row-wise operations can be done with apply.

```{python}
spikes_long['t'].apply(lambda x: x/ms)
```

```{python}
# do that in place
spikes_long['tnum'] = spikes_long['t'].apply(lambda x: x/ms)
```

Now we should be able to plot the spiketimes from the frame.


```{python}
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 'tnum', y = 'neuron:Q')
```

Also altair lets us plot the thing even without transforming the type before as long as you specify that its a quantitative variable (`:Q` tag).

```{python}
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 't:Q', y = 'neuron:Q')
```

## Parameters
We can systematically vary input parameter along neurons.

```{python}
start_scope()

N = 100
tau = 10*ms
v0_max = 3.
duration = 1000*ms

eqs = '''
dv/dt = (v0-v)/tau : 1 (unless refractory)
v0 : 1
'''

G = NeuronGroup(N, eqs, threshold='v>1', reset='v=0', refractory=5*ms, method='exact')
M = SpikeMonitor(G)

G.v0 = 'i*v0_max/(N-1)'
```

The line `v0 : 1` declares a new per-neuron parameter `v0` with units 1 (i.e. dimensionless) for the asymptote of the exponential.
The line `G.v0 = 'i*v0_max/(N-1)'` initialises the value of v0 for each neuron varying from 0 up to `v0_max`. The symbol `i` when it appears in strings like this refers to the neuron index.

```{python}
# now we can run this and extract the spikes
run(duration)
```

```{python}
spikes_wide = pd.DataFrame.\
from_dict(M.all_values()['t'],
          orient = 'index')

# pandas for some reason loves rownames, which pisses me off coming from R
# we need to get the information stored in there!
spikes_wide.index.name = 'neuron'
spikes_wide.reset_index(inplace=True)
# there will be now 1 neuron column with number of neuron rows
# and a column for each spike (as many columns as the maximum number of spikes for a neuron)
# there is an index column and a neuron column, so the max number of spikes
# and the number of data colums is the number of columns -2
spike_max = spikes_wide.shape[1]

# pivot longer by neuron
spikes_long = spikes_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,spike_max-1)),
                               var_name = 'spikeno',
                               value_name = 't')
# tidy and update the thing
spikes_long = spikes_long.sort_values(['neuron', 'spikeno'])
# drop NA values
spikes_long = spikes_long.dropna()
spikes_long['t'] = spikes_long['t'].apply(lambda x: x/ms)
```

```{python}
# make this procedure into a function
def tidy_spike(s_mon_object) :
    """
    This function takes all the data from within a spikemonitor brian object
    and makes it into a tidy pandas frame
    """
    # extract the data to a wide frame
    sdata_wide =  pd.DataFrame.from_dict(s_mon_object.all_values()['t'],orient = 'index')
    sdata_wide.index.name = 'neuron'
    sdata_wide.reset_index(inplace=True)
    # there will be now 1 neuron column with number of neuron rows
    # and a column for each spike (as many columns as the maximum number of spikes for a neuron)
    # there is an index column and a neuron column, so the max number of spikes
    # and the number of data colums is the number of columns -2
    spike_max = spikes_wide.shape[1]
    
    # pivot longer by neuron
    sdata_long = spikes_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,spike_max-1)),
                               var_name = 'spikeno',
                               value_name = 't')
    
    # tidy and update the thing
    sdata_long = sdata_long.sort_values(['neuron', 'spikeno'])
    # drop NA values
    sdata_long = sdata_long.dropna()
    # add a proper numeric time variable
    sdata_long['t_ms'] = sdata_long['t'].apply(lambda x: x/ms)
    
    #return the thing
    return(sdata_long)  
```

```{python}
# test the function
tidy_spike(M)
```

```{python jupyter={'outputs_hidden': True}}
# now plot the thing
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 't:Q',
       y = 'neuron')

```

So apparently altair refuses to make plots with "large" datasets, which actually makes it utterly useless.

```{python}
figure(figsize=(12,4))
subplot(121)
plot(M.t/ms, M.i, '.k')
xlabel('Time (ms)')
ylabel('Neuron index')
subplot(122)
plot(G.v0, M.count/duration)
xlabel('v0')
ylabel('Firing rate (sp/s)');
```

```{python}
# try seaborn instead
import seaborn as sns

sns.relplot(x="t_ms", y="neuron", data=tidy_spike(M), alpha = 0.2);
```

Next, try to reproduce the plot from the example.
We will need to summarise by neuron to get the firing rate.
This should be possible with some group wise-pandas operation.
The syntax for this is `groupby` and `agg`. 

```{python}
tidy_spike(M).groupby('neuron').agg({'spikeno': [max]})
```

This will give rubbish again because python indexes with 0.
In a world of meaningful numbers we need to add 1 to it to make it right.
After the summary we need to run some in place mutation to add 1 to the the max spike.

```{python}
summary_byN = tidy_spike(M).groupby('neuron').agg({'spikeno': [max]})
# add 1
summary_byN = summary_byN.assign(APMAX = summary_byN['spikeno']+1)
# calculate the firing rate (we simulated 1 second)
summary_byN = summary_byN.assign(FRate_hz = summary_byN['spikeno']/1)

```

Inspecting the code of the matplotlib stuff, there is actually by neuron summaries stored in the G and M objects.
Better try to write a tidier for those!

```{python}

```
