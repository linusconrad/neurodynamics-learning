---
output:
  html_document:
    df_print: paged
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---
```{python}
# %load_ext rpy2.ipython
```

```{r}
library(tidyverse)
```


# Learning Simulations
These are my notes for going through the excercises in the neuronal dynamics textbook.


```{python}
# Import brian
from brian2 import *
# data frame support and `tidy` plotting
import pandas as pd
import numpy as np
# ggplot port to python
from plotnine import *
#activate inline use of matplotlib
# %matplotlib inline
```

Define a very simple neuron with this syntax.
The text in the apostrophe environment are the differential equations that define the behaviour.


```{python}
tau = 10*ms             # a time constant
eqs = '''
dv/dt = (1-v)/tau : 1
'''
```

Now we can put the equation into a neuron.
The equation formally typed out:
\begin{equation}
\frac{\partial v}{\partial t} = \frac{(1-v)}{\tau}
\end{equation}
This equation is a simple exponential decay with $\tau$ time constant.

\begin{equation}
v(t) = 1-\exp\left(\frac{-t}{\tau}\right)
\end{equation}

## Simulating and plotting from a single Neuron
Next we assign a Neuron with that voltage equation.
Neurons are always assigned as a neuron group.

```{python}
G = NeuronGroup(1, eqs)
```

Now we can simulate the timecourse with the run command.

```{python}
start_scope()

run(100*ms)
```

Next, we would like to simulate and look at different aspects of the model as it evolves in time.
Variables of the model at a given point in time are referred to as *states* by brian.
The following block simulates and records the time course of voltage based on the model (it should just be an exponential asymptote to 1)



```{python}
start_scope()

G = NeuronGroup(1, eqs, method='exact')
M = StateMonitor(G, 'v', record=0)

run(30*ms)

# plot(M.t/ms, M.v[0])
# xlabel('Time (ms)')
# ylabel('v');
```

State monitor objects are used to store the information of a run.
The neurons have to be specified (here: `record = 0` option) in order to preserve memory.

Now we can introduce spiking behaviour.
Whenever the threshold is reached, voltage gets set to 0, and decays with the defined equation.
These can both be specified in the neuron specification.

```{python}
start_scope()

tau = 10*ms
eqs = '''
dv/dt = (1-v)/tau : 1
'''

G = NeuronGroup(2, eqs, threshold='v>0.8', reset='v = 0', method='exact')

M = StateMonitor(G, 'v', record=True)
spikemon = SpikeMonitor(G)

run(50*ms)
plot(M.t/ms, M.v[0])
xlabel('Time (ms)')
ylabel('v');
```

`StateMonitor` are 2D arrays with the index of the neuron, and the value of the timecourse.
This *should* lend itself to create tidy dataframes from this.
It can be done with the `get.states` syntax (requires pandas).

```{python}
simdata = pd.DataFrame({
    'N': len(M.v),
    't': M.t,
    'V': M.v[0]})

```

This produces the output I want from this one, but is not quite what I want yet, we can go back to it.
Want to have a tidy format dataframe generated from a `StateMonitor` call that can handle multiple variables and neurons.
Should be doable with for loops.

Pseudocode:

* For each neuron in number_neurons
    - do a call to get states that produces a tidy output for that neuron
* then append these tidy frames to each other with a neuron index variable
* assign that to the main environment

Plotnine is the graphing library that should come close to functionaity to ggplot and has a tidy working paradigm.
Try to explore the tidy set created and make a line plot.


This should also be possible with np reshape commands.

```{python}
(ggplot(simdata, aes(x = 't', y = 'V', colour = 'N'))
+ geom_line())
```

Brian can register spikes in the simulation.
This has been done by assigning the spike monitor command.

```{python}
start_scope()

G = NeuronGroup(1, eqs, threshold='v>0.4', reset='v = 0.2', method='exact')

statemon = StateMonitor(G, 'v', record=0)
spikemon = SpikeMonitor(G)

run(50*ms)

# update the simdataframe 
simdata = pd.DataFrame({
    'N': len(statemon.v),
    't': statemon.t,
    'V': statemon.v[0]})
```

```{python}
print('Spike times: %s' % spikemon.t[:])
```

```{python}
spikesdf = pd.DataFrame({'spikes': spikemon.t/ms /1000})
```

Now we can plot the extracted spikes, on top of the timecourse.


```{python}
(ggplot(simdata, aes(x = 't', y = 'V'))
+ geom_line(colour = 'blue')
+ geom_vline(aes(xintercept = 'spikes'), data = spikesdf, linetype = 'dotted')
+ theme_bw())
```

You can introduce refractoryness to the model by adding a refractory dead time.

```{python}
start_scope()

tau = 10*ms
eqs = '''
dv/dt = (1-v)/tau : 1 (unless refractory)
'''

# The neuron with refractory time
G = NeuronGroup(1, eqs, threshold='v>0.8', reset='v = 0', refractory=5*ms, method='exact')

statemon = StateMonitor(G, 'v', record=0)
spikemon = SpikeMonitor(G)

run(50*ms)

# update the simdataframe 
simdata = pd.DataFrame({
    'N': len(statemon.v),
    't': statemon.t,
    'V': statemon.v[0]})

# update the spikes
spikesdf = pd.DataFrame({'spikes': spikemon.t/ms /1000})

# plot it
(ggplot(simdata, aes(x = 't', y = 'V'))
+ geom_line(colour = 'blue')
+ geom_vline(aes(xintercept = 'spikes'), data = spikesdf, linetype = 'dotted')
+ theme_bw())
```

What I did not like about the `plotnine` is that its ggpleot implementation seems to be very sensitive about types and spazzes out immediatly on that, whereas usually R will just throw a warning about continous vs other data.

Altair is another plotting library that looks very clean and is also ignorant about types.

```{python}
import altair as alt

#tc plot
tc_chart = alt.Chart(simdata).mark_line().encode(
    x = 't:Q', 
    y = 'V:Q'  # Quantitative variable
)

#plot of the spike value with vertical line
spike_chart = alt.Chart(spikesdf).mark_rule(strokeDash=[5,5]).encode(
    x = 'spikes:Q'
)

# combine and print
alt.layer(tc_chart,spike_chart)
```

While not as straightforward as ggplot the syntax and output is simple and prety enough.

## Simulating multiple Neurons

Next are going to produce ouput for many neuron.

```{python}
start_scope()
n_neurons = 100         # Number of neurons
tau = 10*ms             # time constant

# same equation as before but the asymtone is now 2
eqs = '''          
dv/dt = (2-v)/tau : 1 
''' 
# A network of 100 neurons
net_100 = NeuronGroup(n_neurons, eqs, threshold='v>1', reset='v=0', method='exact')
# this gives every neuron a different starting value for the voltage at t0
net_100.v = 'rand()' 

spikemon = SpikeMonitor(net_100) # this records the spiketimes

run(50*ms)

```

Now we need to clean the spikemonitor variable.
It contains variables `i` (neuron index) and `t` (spiketime).
They are arrays containing just one vector (dimension `(n_spikes,)`) and have the same length.
Tidying should therefore be easy.

There is a method implemented for `SpikeMonitor` objects that will return a dictionary object of the values, with the umber of the neuron as index.
Problem is it produces an array with a unit.

```{python}
spikemon.all_values()['t'][0]
```

Despite this, pandas allows import, however, the data is now in wide format with the neuron as rows.
So we need to do some wrangling and pivoting.

```{python}
spikes_wide = pd.DataFrame.\
from_dict(spikemon.all_values()['t'],
          orient = 'index')

# pandas for some reason loves rownames, which pisses me off coming from R
# we need to get the information stored in there!
spikes_wide.index.name = 'neuron'
spikes_wide.reset_index(inplace=True)

# pivot longer by neuron
spikes_long = spikes_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,8)),
                               var_name = 'spikeno',
                               value_name = 't')
# tidy and update the thing
spikes_long = spikes_long.sort_values(['neuron', 'spikeno'])
# drop NA values
spikes_long = spikes_long.dropna()
spikes_long
```

This looks fine, but trying to wrangle more I got massive problems because the data types are rubbish.

```{python}
spikes_long.dtypes
```

```{python}
spikes_long['t'].str.split(expand = True)
```

My plan was to treat the compound unt datatype as string and then extract the actual number.
That does not work and throws an error.
To get the number I need to apply the `/ms` syntax from the unit data type from brian.
That works only in a vectorised way if you have a numpy array.
Now it all lives in pandas.
We can do it on an individual datum though.


```{python}
spikes_long['t'][1]

```

```{python}
spikes_long['t'][1]/ms

```

```{python}
#vectorised is gets rid of something but not quite...
spikes_long['t']/ms
```

```{python}
# try assiging a new column (mutate style in R)
spikes_long.assign(spiket = spikes_long['t'] /ms)
```

It does not work, we need to do it row-wise!
Row-wise operations can be done with apply.

```{python}
spikes_long['t'].apply(lambda x: x/ms)
```

```{python}
# do that in place
spikes_long['tnum'] = spikes_long['t'].apply(lambda x: x/ms)
```

Now we should be able to plot the spiketimes from the frame.


```{python}
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 'tnum', y = 'neuron:Q')
```

Also altair lets us plot the thing even without transforming the type before as long as you specify that its a quantitative variable (`:Q` tag).

```{python}
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 't:Q', y = 'neuron:Q')
```

## Parameters
We can systematically vary input parameter along neurons.

```{python}
start_scope()

N = 100
tau = 10*ms
v0_max = 3.
duration = 1000*ms

eqs = '''
dv/dt = (v0-v)/tau : 1 (unless refractory)
v0 : 1
'''

G = NeuronGroup(N, eqs, threshold='v>1', reset='v=0', refractory=5*ms, method='exact')
M = SpikeMonitor(G)

G.v0 = 'i*v0_max/(N-1)'
```

The line `v0 : 1` declares a new per-neuron parameter `v0` with units 1 (i.e. dimensionless) for the asymptote of the exponential.
The line `G.v0 = 'i*v0_max/(N-1)'` initialises the value of v0 for each neuron varying from 0 up to `v0_max`. The symbol `i` when it appears in strings like this refers to the neuron index.

```{python}
# now we can run this and extract the spikes
run(duration)
```

```{python}
spikes_wide = pd.DataFrame.\
from_dict(M.all_values()['t'],
          orient = 'index')

# pandas for some reason loves rownames, which pisses me off coming from R
# we need to get the information stored in there!
spikes_wide.index.name = 'neuron'
spikes_wide.reset_index(inplace=True)
# there will be now 1 neuron column with number of neuron rows
# and a column for each spike (as many columns as the maximum number of spikes for a neuron)
# there is an index column and a neuron column, so the max number of spikes
# and the number of data colums is the number of columns -2
spike_max = spikes_wide.shape[1]

# pivot longer by neuron
spikes_long = spikes_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,spike_max-1)),
                               var_name = 'spikeno',
                               value_name = 't')
# tidy and update the thing
spikes_long = spikes_long.sort_values(['neuron', 'spikeno'])
# drop NA values
spikes_long = spikes_long.dropna()
spikes_long['t'] = spikes_long['t'].apply(lambda x: x/ms)
```

```{python}
# make this procedure into a function
def tidy_spike(s_mon_object) :
    """
    This function takes all the data from within a spikemonitor brian object
    and makes it into a tidy pandas frame
    """
    # extract the data to a wide frame
    sdata_wide =  pd.DataFrame.from_dict(s_mon_object.all_values()['t'],orient = 'index')
    sdata_wide.index.name = 'neuron'
    sdata_wide.reset_index(inplace=True)
    # there will be now 1 neuron column with number of neuron rows
    # and a column for each spike (as many columns as the maximum number of spikes for a neuron)
    # there is an index column and a neuron column, so the max number of spikes
    # and the number of data colums is the number of columns -2
    spike_max = sdata_wide.shape[1]
    
    # pivot longer by neuron
    sdata_long = sdata_wide.melt(id_vars = ('neuron'),
                               value_vars = list(range(0,spike_max-1)),
                               var_name = 'spikeno',
                               value_name = 't')
    
    # tidy and update the thing
    sdata_long = sdata_long.sort_values(['neuron', 'spikeno'])
    # drop NA values
    sdata_long = sdata_long.dropna()
    # add a proper numeric time variable
    sdata_long['t_ms'] = sdata_long['t'].apply(lambda x: x/ms)
    
    #return the thing
    return(sdata_long)  
```

```{python}
# test the function
tidy_spike(M)
```

```{python jupyter={'outputs_hidden': True}}
# now plot the thing
alt.Chart(spikes_long)\
.mark_point()\
.encode(x = 't:Q',
       y = 'neuron')

```

So apparently altair refuses to make plots with "large" datasets, which actually makes it utterly useless.

```{python}
figure(figsize=(12,4))
subplot(121)
plot(M.t/ms, M.i, '.k')
xlabel('Time (ms)')
ylabel('Neuron index')
subplot(122)
plot(G.v0, M.count/duration)
xlabel('v0')
ylabel('Firing rate (sp/s)');
```

```{python}
# try seaborn instead
import seaborn as sns

sns.relplot(x="t_ms", y="neuron", data=tidy_spike(M), alpha = 0.2);
```

Next, try to reproduce the plot from the example.
We will need to summarise by neuron to get the firing rate.
This should be possible with some group wise-pandas operation.
The syntax for this is `groupby` and `agg`. 

```{python}
tidy_spike(M).groupby('neuron').agg({'spikeno': [max]})
```

This will give rubbish again because python indexes with 0.
In a world of meaningful numbers we need to add 1 to it to make it right.
After the summary we need to run some in-place mutation to add 1 to the the max spike.

```{python}
summary_byN = tidy_spike(M).groupby('neuron').agg({'spikeno': [max]})
# add 1
summary_byN = summary_byN.assign(APMAX = summary_byN['spikeno']+1)
# calculate the firing rate (we simulated 1 second)
summary_byN = summary_byN.assign(FRate_hz = summary_byN['spikeno']/1)

```

Inspecting the code of the matplotlib stuff, there is actually by neuron summaries stored in the G and M objects.
Better try to write a tidier for those instead of re-inventing.

```{python}
# firing counts
pd.Series({'A': np.array(M.count)})
```

Also `brian` has a method to extract the neuron parameters in pandas format to start.

```{python}
# extracts all the model starting parameters and the last timepoint
summary_byN = G.get_states(units=False, format='pandas') 
# now we can assign the firing rate data as new columns
summary_byN['nAP'] = pd.Series(np.array(M.count))
# calculate firing rate
summary_byN = summary_byN.assign(FRate_hz = summary_byN['nAP']/1)
summary_byN
```

Now we can plot the systematically varied parameter and the firing rate.

```{python}
sns.relplot(x="v0", y="FRate_hz", data=summary_byN, kind = 'line');
```

To replicate what has been done in the example we need to set the plots side by side.
With seaborn that is done with matplotlib.
Seaborn is  a wrapper to matplotlib and creates plot objects compatible with it.

I had to change the options for plotting.
The previously used `relplot` is meant to produce larger facetted plots that you cant pass to make subplots apparently.

```{python}
import matplotlib.pyplot as plt

f, axes = plt.subplots(1, 2, figsize=(12, 8))
sns.scatterplot(x="t_ms", y="neuron", data=tidy_spike(M), alpha = 0.2, ax=axes[0])
sns.lineplot(x="v0", y="FRate_hz", data=summary_byN, ax=axes[1]);
```

### Introducing a stochastic variable

```{python}
start_scope()

N = 100
tau = 10*ms
v0_max = 1.
duration = 2000*ms
sigma = 0.4

eqs = '''
dv/dt = (v0-v)/tau+sigma*xi*tau**-0.5 : 1 (unless refractory)
v0 : 1
'''

Gnew = NeuronGroup(N, eqs, threshold='v>1', reset='v=0', refractory=5*ms, method='euler')
Mnew = SpikeMonitor(Gnew)

Gnew.v0 = 'i*v0_max/(N-1)'

run(duration)

```

This introduces a gaussian jitter on tau `sigma*xi*tau**-0.5`, why it takes this form exactly I dont know and is beyond me.

```{python}
# Make a tidier for by neuron summaries
def tidy_byN(aneuron, monitorobj):
    """
    This function takes a brian neuron group
    and a spike monitor object of it
    then returns a tidy pandas frame of the start and and values and the firing rates
    """
    # extracts all the model starting parameters and the last timepoint
    byN = aneuron.get_states(units=False, format='pandas')
    
    # duration of the run
    run_dur = byN['t_in_timesteps'][0]*byN['dt'][0]
    # now we can assign the firing rate data as new columns
    byN['nAP'] = pd.Series(np.array(monitorobj.count))
    # calculate firing rate
    byN = byN.assign(FRate_hz = byN['nAP']/run_dur)
    return(byN)
```

```{python}
# now we can use both tidiers to quickly plot everything
f, axes = plt.subplots(1, 2, figsize=(12, 6))
sns.lineplot(x="v0", y="FRate_hz", data= tidy_byN(Gnew, Mnew), ax=axes[1])
sns.scatterplot(x = 't_ms', y = 'neuron', data = tidy_spike(Mnew), alpha = 0.5, ax=axes[0]);
```

# Synapses

```{python}
start_scope()

eqs = '''
dv/dt = (asym-v)/tau : 1
asym : 1
taun : second
'''
G = NeuronGroup(2, eqs, threshold='v>1', reset='v = 0', method='exact')
G.asym = [2, 0]
G.taun = [10, 100]*ms

# Comment these two lines out to see what happens without Synapses
S = Synapses(G, G, on_pre='v_post += 0.2')
S.connect(i=0, j=1)

Mstate = StateMonitor(G, 'v', record=True)

run(100*ms)
```

Next section in the Manual:
We create 2 neurons.
For the parameters we can assign a vector of the length of the number of neurons.
We have different values for the asymtote as well as the time constant.
The First neuron should be exiteable spontaneously, the second not at all.

However, there is a synapse on the second on which will increase `v` on every spike of the first.
It should therefore fire after integrating a couple of spikes.

Now we will need a tidier for the V monitor object.
This may be a bit more complicated.
`monitor.v` is a 2 dimensional array.
There is a row for every Neuron.

```{python}
np.array(Mstate.v).shape
```

I dont know wnough about the arrays to see whether the following will fill the rows in the right way.
Got to try.

```{python}
np.array(Mstate.v).reshape(1000,2)
```

This should be a rectangular table that pandas could handle.

```{python}
# If the following returns the time-series alright we are golden.
# reshape and make a frame
test = pd.DataFrame(np.array(Mstate.v).reshape(1000,2))
test.index.name = 't_dummy'
test.reset_index(inplace=True)

# make long
test = test.melt(id_vars = 't_dummy', value_vars = [0, 1], var_name = "neuron")

sns.relplot(x = 't_dummy',
            y = 'value',
            hue = "neuron",
            col = "neuron",
            kind = "line",
            data = test);
```

It does not and the data from the `np.reshape` was just spread between the two columns.

```{python}
# Its stored per row so we should be able to make a frame without reshaping
# reshape and make a frame
test = pd.DataFrame(np.array(Mstate.v))
test.index.name = 'neuron'
test.reset_index(inplace=True)
test
```

```{python}
# make long
test = test.melt(id_vars = 'neuron')
```

```{python}
sns.relplot(x = 'variable',
            y = 'value',
            hue = "neuron",
            col = "neuron",
            kind = "line",
            data = test);
```

```{python}
#  Try to include the time in this
# the time actually is in column format
testt = pd.DataFrame(np.array(Mstate.t)())
testt
```

```{python}

```
